{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Do_oXLOFjwY6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tensorflow ve görüntü ön işleme adımlarını gerçekleştirmek için keras kütüphanesinden ImageDataGenerator ekledik\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOY_NLtsnkdR"
   },
   "source": [
    "*Resimlerde ön işleme adımının gerçekleşme sebebi overfitting dediğimiz aşırı çoğalma olayını engellemektir.*\n",
    "\n",
    "*Data Preprocessing bölümünde train ve test görüntüleri üzerinde bir ön işleme adımı gerçekleştiriyor olacağız.Bu işlemlerden bahsetmek gerekirse;*\n",
    "\n",
    "*   Eğitim için kullanacağımız görüntülerimizi yakınlaştırma(zoom) ,yatay eksende döndürme(horizontal rotation) , resimler üzerinde ölçeklendirme(rescale) işlemlerini Keras ile birlikte ImageDataGenerator classından yapıyor olacağız.\n",
    "*   Test görüntülerini eğitim de kullanacağımız train görüntüleri gibi yakınlaştırma veya döndürme işlemleri yapmıyoruz yani bunları istemiyoruz çünkü test etmek için orjinal kalmasını istiyor olacağız fakat ölçeklendirme işlemi gerçekleştiriliyor olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hmIRUUHYoqFz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Eğitim veri seti için ön işleme nesnesi oluşturma , oluşturduğumuz train_datagen değişkeni tüm resimlerde dönüşüm işlemi uygulamamızı sağlayan nesne olacaktır.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Eğitim veri setlerine dosya yolu ile ulaşma ve preprocessing nesnesini içersinde kullanmamızı sağlayan fonksiyon\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        '/home/zeyneloglu/Desktop/DeepLearning/CNN/dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y7uv5Pu0zX0"
   },
   "source": [
    "  *Yukarıda gerçekleştirdiğimiz işlemleri kısaca özetlemek gerekirse train_datagen değişkeni aslında ImageDataGeneretor sayesinde resimler üzerinde ölçeklendirme , zoom_range(yakınlaştırma ayarı) , horizontal_flip(yatay dönüş) özelliklerini yapmasını sağlar ve daha birçok özellik vardır ayrıntısına girip bakabiliriz.*\n",
    "\n",
    "  *training_set değişkeni ise hedef resimlerimi seçip onun üzerinden train_datagen nesnesimi uygulamamızı ve aynı şekilde target_size(hedef eğitilecek resim boyutu) , batch_size(model eğitildikten sonra gösterilecek resim sayısı) , class_mode(çıktının türü)--> biz köpek ve kedi mi öğrenmesini istediğimiz için binary diyebiliriz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3-nxXYTy1q8x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test resimleri üzerinde preprocessing işlemi uygulama [train setinde farklı olarak özelliklerin sadece ölçeklendirmesini kullandık çünkü orjinal bir şekilde kalmasını istiyoruz]\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Train setinde yaptığımız gibi aynı işlemleri test setleri içinde uyguluyoruz.\n",
    "test_set= test_datagen.flow_from_directory(\n",
    "        '/home/zeyneloglu/Desktop/DeepLearning/CNN/dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YVQyKpAi6LJs"
   },
   "outputs": [],
   "source": [
    "# CNN nesnesini oluşturduğumuz kısımdır ve oluşturduğumuz nesne ile birlikte diğer adımları gerçekleştiriyor olacağız.\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-YbL4rxF6fmE"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu',input_shape = [64, 64 ,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8rZh_J-6Yk-"
   },
   "source": [
    "*Bu katman CNN’nin ana yapı taşıdır. Resmin özelliklerini\n",
    "algılamaktan sorumludur. Bu katman, görüntüdeki düşük ve yüksek\n",
    "seviyeli özellikleri çıkarmak için resme bazı ﬁtreler uygular. Örneğin,\n",
    "bu ﬁltre kenarları algılayacak bir ﬁltre olabilir. Bu ﬁltreler genellikle\n",
    "çok boyutludur ve piksel değerleri içerirler.(5x5x3) 5 matrisin\n",
    "yükseklik ve genişliğini, 3 matrisin derinliğini temsil eder.*\n",
    "\n",
    "***cnn.add(tf.keras.layers.Conv2D())***: *Yapısı ile evrişim katmanını ekliyor olacağız.Conv2D tensorflow 2 convutional işlemi yani evrişim işlemi gerçekleştirecek olan fonksiyondur.Bunun ile ilgili bilmemiz gereken 3 önemli parametre vardır;*\n",
    "\n",
    "*   filters : Kaç adet filtere haritası kullanılacak ise sayısı\n",
    "*   kernel_size : Kullanılacak olan filtelerin kaça kaçlık olduğunun sayısı \n",
    "*   activation : aktivasyon fonksiyonunu belirttiğimiz parametredir ve genellikle 'relu' kullanılır.\n",
    "*   input_shape : Görüntünün kaça kaçlık olduğunu ve derinliği [Bunu preprocessing bölümünde target size de yazdığımız sayıdır  , derinliği ise resimler RGB olduğunu için 3'dür diyebiliriz.**Sadece ilk eklendiğinde girilir tekrar evrişim katmanı eklemek istediğimizde bunu parametre olarak eklemeyiz.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WP7PuzaF-RcL"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjkTmLZj-PB_"
   },
   "source": [
    "*Bu katman, CovNet’teki ardışık convolutional katmanları arasına\n",
    "sıklıkla eklenen bir katmandır. Bu katmanın görevi, gösterimin\n",
    "kayma boyutunu ve ağ içindeki parametreleri ve hesaplama sayısını\n",
    "azaltmak içindir. Bu sayede ağdaki uyumsuzluk kontrol edilmiş olur.\n",
    "Birçok Pooling işlemleri vardır, fakat en popüleri max pooling’dir.\n",
    "Yine aynı prensipte çalışan average pooling, ve L2-norm pooling\n",
    "algoritmalarıda vardır.Burada MaxPool işlemini uygalayacağız.*\n",
    "\n",
    "***cnn.add(tf.keras.layers.MaxPool2D())*** : *Yapısı ile pooling(havuzlama) katmanını ekleyebilriz.Önemli iki parametresi bulunmaktadır;*\n",
    "\n",
    "\n",
    "*   pool_size : pool yapacak matrixin kaça kaçlık boyuta sahip olduğunu yazarız\n",
    "*   strides : input üzerinde gezinirken kaç adım kaymasını istediğimiz sayıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dIgSdO5G_A-W"
   },
   "outputs": [],
   "source": [
    "# input_shape parametresini eklemiyoruz çünkü bu bir input girişi değil tekrar bir convolutional katmanı ekliyoruz\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx3xPgI6_lVH"
   },
   "source": [
    "### Adding a second pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Aiknmkhb_qgU"
   },
   "outputs": [],
   "source": [
    "# İkinci bir Evrişim (convolutional) işleminden sonra tekrar pooling işlemi gerçekleştiriyoruz.\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vcu1CxoyBGE3"
   },
   "outputs": [],
   "source": [
    "# Yapay sinir ağı oluşturmak için son adım olarak işlemlerin sonucunu tek boyutlu matrix yani vektör haline getirir.\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbMI4JjQBDoH"
   },
   "source": [
    "*Bu katmanın görevi basitçe, son ve en önemli katman olan Fully\n",
    "Connected Layer’ın girişindeki verileri hazırlamaktır. Genel olarak,\n",
    "sinir ağları, giriş verilerini tek boyutlu bir diziden alır. Bu sinir\n",
    "ağındaki veriler ise Convolutional ve Pooling katmanından gelen\n",
    "matrixlerin tek boyutlu diziye çevrilmiş halidir.*\n",
    "\n",
    "**cnn.add(tf.keras.layers.Flatten())** : *Yapısı ile gerçekleştirilir ve parametre almaz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeFWY_jsBx2z"
   },
   "source": [
    "*Bu katman ConvNet’in son ve en önemli katmanıdır. Verileri\n",
    "Flattening işleminden alır ve Sinir ağı yoluyla öğrenme işlemini\n",
    "geçekleştirir.*\n",
    "\n",
    "*ANN yapısında oluşturduğumuz gibi hidden layer katmanlarını oluşturuyoruz resim üzerinde gerçekleştirdiğimiz adımları Flattening adımı ile vektör haline getirdik ve artık sanki bir yapay sinir ağı eğitiyormuş gibi davranabiliyoruz.\n",
    "\n",
    "\n",
    "*   units : nöron sayısı\n",
    "*   activation : aktivasyon fonksiyonu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yUq9OObnBe5D"
   },
   "outputs": [],
   "source": [
    "# hidden layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128 , activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-Si6nRA_CImQ"
   },
   "outputs": [],
   "source": [
    "#  output layer [binary bir sonuç alacağımız için ya köpek diyecek ya da kedi bu yüzden activation fonksiyonu olarak sigmoid kullanmak daha doğru olacaktır output layer için]\n",
    "cnn.add(tf.keras.layers.Dense(units=1 , activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q646Ppg5JH5Q"
   },
   "source": [
    "Bu bölümde oluşturduğumuz yapay sinir ağı modelini veri setimiz için eğitme işlemi gerçekleştiriyor olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k-EMeKSJAka"
   },
   "source": [
    "CNN derleme işlemi gerçekleştiriyor olacağız.Bunun için **cnn.compile()** fonksiyonunu kullanıyor olacağız.\n",
    "\n",
    "**optimizer:** optime eden fonksiyondur ve en iyilerinden biri **adam** fonksiyonudur.\n",
    "\n",
    "**loss:**: kayıp fonksiyonu şuan biz veri setimizde binary bir sonuç yani (ikili bir sonuc 0 ve 1 den oluşan) değer alacağımız için \n",
    "**binary_crossentropy** kullanmamız uygun olacaktır fakat kategorik bir output alacak isek **category_crossentropy** kullanmamız gerecektir.\n",
    "\n",
    "**metrics**: eğitim sırasında görmek istediğimiz metrics türlerini bir liste içerisinde yazabilir şuan için accuracy(yani doğruluk skorunu) yazdık fakat araştırarak diğer metrics türlerinide yazabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mliWW8U4JCBm"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss ='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JyGxh3ZJNHd"
   },
   "source": [
    "Veri setinin artık eğitme kısmına geldik bunun için eğitim setleri yukarıda oluşturduğumuz traning_set olacaktır ve test setleri ise parametre olarak validation_set parametresinde yer alır, makine öğrenmesinde olduğu gibi burada da fit etme işlemini kullanıyor olacağız.\n",
    "\n",
    "**ann.fit(x = traning_set , validation_data = test_set , batch_size , epochs)** parametlerini almaktadır.\n",
    "\n",
    "**batch_size**: kendi deneylerimiz sonucu optimum değeri bulabiliriz bunun ayrıntılarına internet üzerinde araştırabiliriz eğer hiçbir şey bilmiyorsak 32 uygun bir değerdir.\n",
    "\n",
    "**epochs**: eğitim adım sayısı gibi düşünebilirz çok fazla olması overfitting sebep olabilir bu yüzden optimum bir sonuç yazmak önemlidir bu veri seti için 100 değeri gireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pUYw7Re-JixC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 22s 87ms/step - loss: 0.6915 - accuracy: 0.5523 - val_loss: 0.6504 - val_accuracy: 0.6460\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 21s 86ms/step - loss: 0.6374 - accuracy: 0.6428 - val_loss: 0.6123 - val_accuracy: 0.6950\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 23s 92ms/step - loss: 0.5795 - accuracy: 0.6991 - val_loss: 0.5387 - val_accuracy: 0.7480\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 23s 90ms/step - loss: 0.5322 - accuracy: 0.7324 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 23s 90ms/step - loss: 0.5126 - accuracy: 0.7502 - val_loss: 0.4946 - val_accuracy: 0.7600\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 23s 93ms/step - loss: 0.4829 - accuracy: 0.7681 - val_loss: 0.5027 - val_accuracy: 0.7595\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 22s 90ms/step - loss: 0.4789 - accuracy: 0.7715 - val_loss: 0.4828 - val_accuracy: 0.7730\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 23s 90ms/step - loss: 0.4496 - accuracy: 0.7875 - val_loss: 0.4704 - val_accuracy: 0.7750\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.4447 - accuracy: 0.7851 - val_loss: 0.6052 - val_accuracy: 0.7360\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 22s 89ms/step - loss: 0.4298 - accuracy: 0.7994 - val_loss: 0.4578 - val_accuracy: 0.8005\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 22s 89ms/step - loss: 0.4199 - accuracy: 0.8039 - val_loss: 0.4816 - val_accuracy: 0.7680\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.4020 - accuracy: 0.8125 - val_loss: 0.4653 - val_accuracy: 0.7880\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.3933 - accuracy: 0.8186 - val_loss: 0.4502 - val_accuracy: 0.8055\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.3763 - accuracy: 0.8317 - val_loss: 0.4505 - val_accuracy: 0.7920\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.3675 - accuracy: 0.8364 - val_loss: 0.4401 - val_accuracy: 0.8145\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.3497 - accuracy: 0.8449 - val_loss: 0.4529 - val_accuracy: 0.7990\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 21s 85ms/step - loss: 0.3540 - accuracy: 0.8401 - val_loss: 0.4378 - val_accuracy: 0.8060\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 20s 80ms/step - loss: 0.3436 - accuracy: 0.8490 - val_loss: 0.4612 - val_accuracy: 0.7990\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 21s 85ms/step - loss: 0.3245 - accuracy: 0.8555 - val_loss: 0.4943 - val_accuracy: 0.8005\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.3225 - accuracy: 0.8586 - val_loss: 0.4647 - val_accuracy: 0.8045\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.3101 - accuracy: 0.8644 - val_loss: 0.5144 - val_accuracy: 0.7925\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 22s 86ms/step - loss: 0.3051 - accuracy: 0.8652 - val_loss: 0.4826 - val_accuracy: 0.8005\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.2840 - accuracy: 0.8792 - val_loss: 0.4811 - val_accuracy: 0.8085\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 22s 87ms/step - loss: 0.2734 - accuracy: 0.8826 - val_loss: 0.4592 - val_accuracy: 0.8135\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 22s 87ms/step - loss: 0.2715 - accuracy: 0.8863 - val_loss: 0.5001 - val_accuracy: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25d5083880>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs sayısı seçimi deneme yanılma ile ortaya çıkartılması gerekmektedir.Fakat biz genel bir sayı verdik.\n",
    "cnn.fit(x = training_set , validation_data = test_set , epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f98VDhSePqnV"
   },
   "source": [
    "*Bu bölümde tek bir resim yükleyerek resmin kedi mi yoksa köpek mi olduğunu tahmin etme işlemi gerçekleştiriyor olacağız.Bu işlemi gerçekleştirmek için birkaç adım izlememiz gerekmektedir;*\n",
    "\n",
    "\n",
    "*   *İlk olarak resimi yükleme işlemi gerçekleştiriyor olacağız ve bu işlemi keras kütüphanesi içerisinden preprocessing ile birlikte image sınıfından* **load_image(resmin_url , target_size)** *fonksiyonu ile gerçekleştiriyor olacağız.*\n",
    "*   *Resimi ekledikten sonra bu resmi vektör haline yani dizi haline getirmemiz gerekmektedir çünkü biz biliyoruzki resimler flatting bölümünde tek boyutulu matrixler haline gelmektedir.*\n",
    "*   *Dizi haline getirdikten sonra numpy kütüphanesi sayesinde tahmin yapacağımız resmimizi başta giriş resimlerinin boyutu (target_size) belirlediysek o boyutta olması için* **np.expand_dims(test_image, axis = 0)** *şeklinde gösteriyor olacağız.*\n",
    "\n",
    "*   **result = cnn.predict(test_image)** *fonksiyonu ile bu değeri bir değişkene eşitleme işlemi yapıyor olacağız.*\n",
    "*   *Tahmin değerlerine tam ulaşmak için* **training_set.class_indices**\n",
    "*   if result[0][0] == 1: --> ilk [0] tahmin değerlerine girer ve ikinci [0] dog [1] kediyi temsil etmektedir.\n",
    " *      prediction = 'dog'\n",
    "*    else:\n",
    " *     prediction = 'cat' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IAwb7GhKSCd4"
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneler\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Tahmin edilecek resmi yükleme\n",
    "test_image = image.load_img('/home/zeyneloglu/Desktop/DeepLearning/CNN/dataset/single_prediction/cat_or_dog_8.jpg', target_size = (64, 64))\n",
    "# Diziye çevirme\n",
    "test_image = image.img_to_array(test_image)\n",
    "# Target size uyumunu gerçekleştirme\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "# Tahmin sonucunu değişkene aktarma\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "# Tahmin değerini alma\n",
    "if result[0][0] > 0.5:\n",
    "  prediction = 'dog'  \n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "wemmJxXrSt7h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN Beginning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
